10/24/23

-Need to "explode" the parcel data
-Need to drop blocks/parcels with zero population, or low population, but not sure at which point.
-could I develop a composite mhps layer that is the best of both? Could I intersect the points with roads to filter/choose?
 
-maybe before doing that find the double hits and compare versions
-going to have to do the comparison before 

-A consistent problem occurs when a county gov includes streets as parcels, then that particular county has a lot of mismatches.


-Next: find out which mhps matched in each version but did not match in the other. 


-what if I dropped all rows of the parcel data where length of the geometry exceeds some typical amount? This may help get rid of roads.... DID This and worked.

Next:



Redo the compare versions for DOUBLE HITS (same mhp same parcel), DIFFERENCES (same mhp different parcel); UNIQUES (mhps parcels not in the other dataset), NON-MATCH mhps

-Overall 684 MHPs in Colorado, regeocoded mhps got 442 matches, original got 211 matches. 178 mhps in common were matched in each version, but not always to the same parcel: 72 were DIFFERENCES, 106 DOUBLE HITS. (These were found by merging). 52/72 original was correct; 7 regeocoded were correct; 7 were either both wrong, 6 both right. 
** Originals most often correct... maybe start w/ originals then supplement with regeocoded?

Next: examine regeocoded uniques?

UNIQUES: 300 UNIQUES overall, 264 UNIQUE mhp matches in regeocoded data, 36 UNIQUE mhp matches in original data.

NON-MATCH: 209 not matched by either version. 


11/2/23
********
Reviewed the accuracy of regeocoded mhp-parcels and original mhp-parcels:
Original much more accurate!

Regeocoded had 442 matches, but 190 of them were wrong, making a 57% accuracy rate

Original had 211 matches, but only 25 were wrong! 88% accuracy rate

Among the unique regeocoded MHP-parcels (mhp-parcel not matched using the original data but matched in the regeocoded), 130 out of 264 were WRONG, only 50% match rate. So these weren't accurately matched anyway. 

However, of the 684 MHPs, 211 matched (88% accurate). That's only 30%. (or 186 matched/27% if you account for accuracy rate)

11/29/23
*********

Changed strategy to using a near join. This works better, however, I've discovered that 
that the geometry length zscore filtering method is sometimes removing good ones
and leaving in bad ones. Need to refine this before I can really determine
how well the near is working.

For tomorrow: try simplifying geometries prior to calculating the geometry length zscore

What's going on with Larimer county???
Add a line to drop dupes based on apn2 if apn1 is null? no
dedupe based on geometry column? <<<Did this

12/1/23
********
Yesterday figured out how incorporate interior geometries and use that as a filtering mechanism 
(get rid of street grids)

Today worked on integrating microsoft buildings data. 
-split data I already have into correct directories
-created a summarize within function to count buildigns within parcels, 
-incorporated this into parcelMHPJoin function
-discovered that broomfield county was missing (08014). 
-My source data for county fips and county names was old!!!
-Fix Monday, then continue evaluating if buildings can be used

12/4/23
********
Got buildings successfully incorporated, and now used to filter.
Steps: 
1) drop all parcels w/ interior geom length greater than 20
2) drop all parcels where external geometry Z score > 3 AND sumWithin (buildings count) < 10

This is working well

To do tomorrow:
-investigate all parcels w/ zero sum_Within
-select double hits based on sum_within or nearest or some combination
-email Emily
-email Kevin Worthington


12/5/23

-trying to determine criteria for deciding which parcel to keep
-increase near distance to 10 (perhaps examine a second round of results at 15 m)
-choose the one with buildings--at least 2
-if no double hit, just leave it in(?) TBD... or perhaps not. Ask Emily?
-if both (or multiple) have a lot of buildigs, keep both
-if both zero buildings, drop both
-should just drop all parcels w/ zero buidings?

-Got rid of all 0s, compared all double hits and selected the one
with the most buildings, dropped all remaining 1s.

-95% correct!

12/6/23
********

-multipart polygon rabbit hole
-tomorrow: check differences between explode results and multipart results

12/7/23
********
Examined multipart vs exploded: Multipart is better!

expanded near join to 15m, need to examine the results more closely:
-split off matches from 15m join that were not matched in 10m join

-oddly, it seems that when I combine the mh-parcel files into one state wide file,
it stores all geometries as multigeometry. I don't know why.


For 12/12/23
********
-Drop all parcels w/ fewer than 5 buildings. *all of the matches with 4 were wrong half the time.
-see what the match rate is when accounting for counties where parcel data is missing
-need to figure out warnings.

Questions for Emily:
Leave in duplicate geometries? (that is, when 2 points match with the same parcel)
How many mobile homes qualifies a parcel as an MHP? (< 30, but I'll start w/ 20)

To do:
Work on filtering mechanism when there are parcels matched with multiple mhps.

12/13/23
*********

Turned out the filtering mechanism was not really the place to address the
problem of wrong matches for right reason. This all stemmed from the duplicate geometries question.

Ended up reworking the near join process, breaking things up into smaller functions as well
-Turns out the near was going the opposite direction than I though (parcel to mhp), 
-switched to mhp-parcel nearest, then joined them back to parcel with just a table join
-then took the unmatched and did a parcel-mhp nearest to grab the results
-then concatted the first join and second join
-same results (well, slightly improved) but no more 'right for the wrong reason' matches.

Tomorrow: select only medium+ (20 or 30 minimum), carry over some more columns from original mhp data
into final data.

1/2/24

-Working well.

Questions for Emily:
-Fields to carry over?
-How to approach/figure out success rate in identifying parcels.

1/5/24

Need to fix: get rid of MHP_{fips}.csv files, resplit the original state file into counties with that name
Rename output so it doesn't overwrite
figure out problem with field types (fips getting messed up)
Get clarity on what emily wants.

1/31/24
Been testing matching just on simple table merge w/ apn, but only works about 50% 
of the time, worse than my algorithm. 

-Need to check accuracy of the correct 50% though...
-How can I incorporate this?
-To do:
1. incorporate apn
2. incorporate building/unit numbers as a check
3. feasible to incorporate ownership? 

-First run APN match (keep non matches) and add column T/F for APN match
-Then run geo matching process, resulting in some double matches
-Group parcels by... geom?... and drop duplicates where APN match is False

-Need to sum sum_within when grouped by APN, how different from MH_UNITS... 
-if very different, FLAG for inspection? Or drop if APN-MHAPN differ? Or if APN match is false?

2/1/24

-Incorporated apn pre merge followed by geo merge, but have not weeded out
 duplicated parcels yet.

-need to compute sum_within/MH_UNITS proportions into a new columns, perhaps sort by
 then can drop below a percentage???

 2/7/24
 -Finally got the sum_within/MH_units filter worked out yesterday--works!!!! 
 -downloaded all 2010 and 2000 blocks boundaries for Colorado
 -integrated 2000 and 2010 workflows into parcelfunks, but untested
 -need to finish working 2000 and 2010 workflows into main.py


 3/4/24

-been working on reincorporating the original mhp data.
-during near select on parcelMHPJoin function, 'tempID' column is not found... why not? 
-and why does it work on the parcelCOSTARjoin version?

3/7/24
-okay! got all of these issues sorted. Is performing as it should.
Next steps:
-start prepping for scale up... 
-Meet w/ Andy
-document various functions... reorganize?
-inventory 2024 parcel data
-how to move, where to put it
-download buildings and blocks data or just grab them?

3/11/24
- work on doc strings


3/13/24
-Been testing on alpine
-with a few mods (switch path.split('\\')[-1] to '/'),
-everything worked on Adams county!

3/26/24
-quick test to see how it worked on multiple (2) counties, works fine.

3/27/24
-started work on getting buildings to scratch space.
-need to generate cfips & sfips lists from parcel inventory, but 2024 data is at work.

5/10/24
-switched all package management to mamba and blew up conda last month
-buildings_getter.py works with buildings.sh
-something is going with bash terminal in vscode, looking in the wrong place for proj
-has to do w/ conda... which I destroyed
-when running in bash, things mess up, 
-scripts work in powershell though, so scripts are good, env variables messed up?

to do:
-plan/get buildings, parcels, and censu tracts onto alpine scratch

6/6/24
-parcel, blocks, buildings data all loaded onto scratch/alpine
-need to get HIFLD mhp data, prep, upload, and split/
-need COSTAR mhp data, prep, upload, and split using parcel inventory list
-run small tests on parcelPipe to make sure I didn't mess up naming conventions
 with renaming of MHP_OG to HIFLD.
-run data inventory to make sure everything is there.
-upload parcelPipe.py to projects/phwh9568/mh_v1
-getting close.

6/13/24
-working on script that will select the most complete county parcels layer
-2022 zipped files are nested, but 2023 are not... 

Also to do:
-change crs for Hawaii and Alaska


6/18/24
-parcel tester is working
-to do:
-change crs for hawaii and Alaska
-run inventory checks on 2021 and 2022 parcel data
-git rid of LA county and Harris county tx in 2021 and 2022 data
-can't find my inventory script...  got it: zipcheck.py

6/20/24
-Note that you need to combine the 3 shapefiles for cook county illinois (chicago) 
fips 17032 into one GPKG and modify pipeline script. needs to be some combination of 2023 and 2021(?)
-Ditto San Diego, use 2021 data
-resolved all(I think) inventory issues w 2021 2022 data
-fixed crs for Hawaii and Alaska (have not tested...)
-Double check LA county 06037 and Harris County 48201--these are fine. got rid of 21 and 22 for both. 
-LA county 2023 complete, only southern half of Harris County in all three datasets. Oh well?

6/28/24
Problem counties:
LA county: 06037: Acquired, has APN. Saved as GPKG, not yet uploaded
San Diego county: 06073 (need to combine N & S): Acquired, has APN. Uploaded as shp. DONE.
Wayne County MI: 26163: Acquired, no APN column. APN column added(empty), uploaded as shp. DONE.
Cook County IL: 17031: Acquired, no APN column. Saved as GPKG, added APN col(empty), not yet uploaded.
Harris County TX: 48201: Acquired, no APN column. Saved as GPKG, added APN col(empty), not yet uploaded

To do:
-Fix problem counties--done except upload gpkgs: DONE
-update inventory script to include final output layers: DONE
-Add south dakota costar transactions: DONE
-remove problem parcel data county directories from scratch?: Nah
-remove problem counties from US_counties.txt: I think it's fine to leave them
... should be ready to run at that point? 

Bad data counties:
17137, empty shp
21049, bad data
21093, empty shp 
21111, bad data 
26163, empty shp fixed
35059, empty shp 
36025, bad data 
46003, empty shp 
46009, bad data 
46045, bad data 
48125, empty shp 
56041, bad zip file


7/1/24:
Okay, ran main workflow on Colorado, noticed Larimer county 08069 was missing. Turns out this is not in the 2023 inventory but in earlier. 
Need to find out which counties might be missing from the 2023 inventory that are present in earlier years, 
then rerun parcel_test/split, buildings getter, blocks getter, and then mobile home splitter on just these counties.
Goddamn you parcelatlas fuck heads.

The following 2023 counties were missing but present in 21 or 22:
06047
06053
06059
06063
06109
08047
08069
10003
10005
11001
15005
17067
18157
18163
19083
22013
32003
38105
55029

Need to get buildings and census blocks for all of the above... 

While fixing above, discovered that 2022 zip files had .ZIP extension, and were not being analyzed by the parcel_tester.py. 

7/2 to do:
Rerun parcel_tester.py on ALL counties. Replace US_counties.txt with updated one that includes the above 
-note: exempt 18157 from the list for parcel_tester, but add back for subsequent steps
When rerunning parcel_tester, need to delete all the old parcels.shp files from directories, but need to keep the following then pass on them:
-06037, all good
-06073, all good
-26163, all good
-17031, all good
-48201, all good
-18157, needs buildings, blocks, hifld, costar
--Just remove these from the fips input list, get rid of loop in woops.py and delete using sbatch array
DONE
--Then get buildings and blocks for the list above.
DONE
--Then get costar and hifld mhp points into place for the list above.
DONE
--Then ready?

I think we're ready.

7/3:
ran all counties. Some problems, but mostly worked.
-None type geometries throw error during prefilter int/ext length function
    -should be fixed by dropping rows with None type geoms
-alaska/hawaii blocks in wrong crs, so no unions.
    -should be fixed by if/el statements for crs in unionWorker func
-parcels in gpkgs didn't work.

Next:
- run ones that did not produce {fips}.gpkg
- LA worked. Problem was OOM error.
- problem is with empty APN columns. See line 156.
    -perhaps a fake 'APN'? Or, If APNs are None, use different column for pivot?

7/9/

-looking at counties that had COSTAR or HIFLD data but did not get a match...
-NYC counties: not legit, all of the parcels where these supposed parks are were filtered out
-Philly: 1, but seems long abandoned?

-Lake County IL: Lake County OH was in the zip folder, not IL. IL is an esri parcel fabric,
 need to open up arc to get it I guess?

To do:
find out how many costar mhps are in each of thse problem counties. That can help as a decision point.

7/17:
down to only a handful of rando counties broken, all <10 costar parks 
(95 parks total across 45 counties)

to do:
-compile county level data into national files.


7/19:
Discovered random line removing outlier interior geoms was
missing from the parcelPipe.py. 
-Rerunning everything as a result.

7/29:
Everything has run and compiling scripts work.
-need to drop exterior lens over 1000
-should I just make the list and run only some those counties, then recompile? yes. any reason not to? 
12095
37181
45015
38053
45075
24023
42007
39149
54109
32003
37045
13021
22085
01087
22085
53067
22045
21151
47073
12069
42021
19005
12107
Well, it makes for inconsistency in how all these data were processed since it affects the z score.
shit.

throw out:
Mitchell County NC 37121
Tipton County IN 18159
Perry County IN 18123
Switzerland County IN 18155
Winnebago County WI 55139
Grand Isle County VT 50013
Sargent County ND 38081
Calcasieu Parish LA 22019

7/30.
Okay, reran everything. Dropped parcels with exterior len greater than 1000, then 

oh fuck. I should have dropped the 1000+ extLen1 rows THEN calculated zscores.

7/31
Okay, reran everything again. Now ready to combine everything and ship off.

